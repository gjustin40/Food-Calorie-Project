{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# data_path = '../../data/caffe_drinks/'\n",
    "# class_names = os.listdir(data_path)\n",
    "\n",
    "# for name in class_names:\n",
    "#     image_list = glob.glob(data_path + name + '/*')\n",
    "    \n",
    "#     for image in image_list:\n",
    "#         img = Image.open(image)\n",
    "#         img_channel = len(img.split())\n",
    "        \n",
    "#         if img_channel != 3:\n",
    "#             print(image)\n",
    "    \n",
    "#     print(name, 'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are Using : cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x204d5f84330>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH = 50\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 4\n",
    "TEST_SIZE = 0.20\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9\n",
    "FOLD_N = 2\n",
    "CLASS_NUM = 9\n",
    "\n",
    "# GPU 여부\n",
    "if torch.cuda.is_available(): device = torch.device('cuda') \n",
    "else: device = torch.device('cpu')\n",
    "print('We are Using :', device)\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperDataset:\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataset[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, device, dataloader):\n",
    "    total_loss, accuracy = 0, 0\n",
    "    total_samples, correct_samples = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.detach().cpu()\n",
    "        \n",
    "        preds = outputs.argmax(1)\n",
    "        total_samples += preds.size()[0]\n",
    "        correct_samples += preds.eq(labels.view_as(preds)).cpu().sum().item()\n",
    "        \n",
    "    accuracy = (correct_samples / total_samples) * 100\n",
    "    \n",
    "    return total_loss, accuracy\n",
    "\n",
    "def test(model, loss_func, device, dataloader):\n",
    "    total_loss, accuracy = 0, 0\n",
    "    total_samples, correct_samples = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = loss_func(outputs, labels)\n",
    "            total_loss += loss.detach().cpu()\n",
    "\n",
    "            preds = outputs.argmax(1)\n",
    "            total_samples += preds.size()[0]\n",
    "            correct_samples += preds.eq(labels.view_as(preds)).cpu().sum().item()\n",
    "\n",
    "        accuracy = (correct_samples / total_samples) * 100  \n",
    "    \n",
    "    return total_loss, accuracy\n",
    "\n",
    "\n",
    "def draw_matrix(model, device, dataloader, class_num):\n",
    "    total_samples, correct_samples = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    confusion_matrix = torch.zeros(CLASS_NUM, CLASS_NUM)\n",
    "       \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            preds = outputs.argmax(1)\n",
    "            total_samples += preds.size()[0]\n",
    "            correct_samples += preds.eq(labels.view_as(preds)).cpu().sum().item()\n",
    "                 \n",
    "            # Make Confusion Matrix\n",
    "            for row, col in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[row.long(), col.long()] += 1\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/caffe_drinks/'\n",
    "dataset = ImageFolder(root=data_path)\n",
    "\n",
    "kfold = KFold(n_splits=FOLD_N, shuffle=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAffine(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch 1 / 50 ---- train_loss: 115.6541 ---- train_acc: 49.9075 ---- test_loss: 651.1437 ---- test_acc: 72.3404\n",
      "Epoch 2 / 50 ---- train_loss: 68.8921 ---- train_acc: 77.6596 ---- test_loss: 448.8478 ---- test_acc: 82.3312\n",
      "Epoch 3 / 50 ---- train_loss: 54.0026 ---- train_acc: 81.0361 ---- test_loss: 373.1538 ---- test_acc: 84.4126\n",
      "Epoch 4 / 50 ---- train_loss: 45.3266 ---- train_acc: 84.3201 ---- test_loss: 326.1725 ---- test_acc: 85.0139\n",
      "Epoch 5 / 50 ---- train_loss: 41.0691 ---- train_acc: 84.1813 ---- test_loss: 307.1818 ---- test_acc: 85.0139\n",
      "Epoch 6 / 50 ---- train_loss: 38.1304 ---- train_acc: 85.6614 ---- test_loss: 287.5931 ---- test_acc: 85.5227\n",
      "Epoch 7 / 50 ---- train_loss: 34.1738 ---- train_acc: 87.0028 ---- test_loss: 264.3050 ---- test_acc: 86.4477\n",
      "Epoch 8 / 50 ---- train_loss: 32.5792 ---- train_acc: 86.7253 ---- test_loss: 254.1192 ---- test_acc: 86.9103\n",
      "Epoch 9 / 50 ---- train_loss: 31.4610 ---- train_acc: 87.0953 ---- test_loss: 245.7675 ---- test_acc: 86.6327\n",
      "Epoch 10 / 50 ---- train_loss: 30.2288 ---- train_acc: 87.8816 ---- test_loss: 238.9928 ---- test_acc: 86.9565\n",
      "Epoch 11 / 50 ---- train_loss: 29.7878 ---- train_acc: 88.0204 ---- test_loss: 235.8207 ---- test_acc: 87.2340\n",
      "Epoch 12 / 50 ---- train_loss: 27.9362 ---- train_acc: 88.4829 ---- test_loss: 225.8926 ---- test_acc: 87.1878\n",
      "Epoch 13 / 50 ---- train_loss: 28.0934 ---- train_acc: 87.7891 ---- test_loss: 224.1960 ---- test_acc: 87.6503\n",
      "Epoch 14 / 50 ---- train_loss: 26.7389 ---- train_acc: 88.4366 ---- test_loss: 225.2958 ---- test_acc: 87.4191\n",
      "Epoch 15 / 50 ---- train_loss: 26.9347 ---- train_acc: 88.8067 ---- test_loss: 221.0377 ---- test_acc: 87.0490\n",
      "Epoch 16 / 50 ---- train_loss: 26.1070 ---- train_acc: 88.4829 ---- test_loss: 216.9620 ---- test_acc: 87.4653\n",
      "Epoch 17 / 50 ---- train_loss: 25.4239 ---- train_acc: 89.5467 ---- test_loss: 211.2994 ---- test_acc: 87.8353\n",
      "Epoch 18 / 50 ---- train_loss: 25.3822 ---- train_acc: 89.8242 ---- test_loss: 213.2962 ---- test_acc: 87.6503\n",
      "Epoch 19 / 50 ---- train_loss: 25.2009 ---- train_acc: 88.7142 ---- test_loss: 213.2129 ---- test_acc: 87.6503\n",
      "Epoch 20 / 50 ---- train_loss: 25.2288 ---- train_acc: 88.6216 ---- test_loss: 201.7934 ---- test_acc: 88.1591\n",
      "Epoch 21 / 50 ---- train_loss: 23.3793 ---- train_acc: 89.6855 ---- test_loss: 214.5009 ---- test_acc: 87.0490\n",
      "Epoch 22 / 50 ---- train_loss: 23.6951 ---- train_acc: 89.0379 ---- test_loss: 210.1829 ---- test_acc: 87.5116\n",
      "Epoch 23 / 50 ---- train_loss: 22.5567 ---- train_acc: 90.4255 ---- test_loss: 208.5280 ---- test_acc: 87.8353\n",
      "Epoch 24 / 50 ---- train_loss: 22.0835 ---- train_acc: 90.1018 ---- test_loss: 203.1882 ---- test_acc: 87.6503\n",
      "Epoch 25 / 50 ---- train_loss: 21.4210 ---- train_acc: 90.7493 ---- test_loss: 201.7500 ---- test_acc: 87.7428\n",
      "Epoch 26 / 50 ---- train_loss: 22.1537 ---- train_acc: 89.9630 ---- test_loss: 202.1717 ---- test_acc: 87.7428\n",
      "Epoch 27 / 50 ---- train_loss: 21.3181 ---- train_acc: 90.5180 ---- test_loss: 204.0310 ---- test_acc: 87.6041\n",
      "Epoch 28 / 50 ---- train_loss: 21.7997 ---- train_acc: 89.8705 ---- test_loss: 206.2858 ---- test_acc: 87.4191\n",
      "Epoch 29 / 50 ---- train_loss: 21.4285 ---- train_acc: 90.9343 ---- test_loss: 197.8252 ---- test_acc: 87.8816\n",
      "Epoch 30 / 50 ---- train_loss: 20.5958 ---- train_acc: 90.3793 ---- test_loss: 195.0755 ---- test_acc: 87.7428\n",
      "Epoch 31 / 50 ---- train_loss: 20.5239 ---- train_acc: 90.5180 ---- test_loss: 193.2467 ---- test_acc: 88.3441\n",
      "Epoch 32 / 50 ---- train_loss: 20.7309 ---- train_acc: 90.1480 ---- test_loss: 199.7298 ---- test_acc: 87.6503\n",
      "Epoch 33 / 50 ---- train_loss: 20.9219 ---- train_acc: 90.3793 ---- test_loss: 195.9323 ---- test_acc: 88.0666\n",
      "Epoch 34 / 50 ---- train_loss: 20.4473 ---- train_acc: 91.2581 ---- test_loss: 192.0372 ---- test_acc: 88.2516\n",
      "Epoch 35 / 50 ---- train_loss: 20.1479 ---- train_acc: 91.2581 ---- test_loss: 196.4465 ---- test_acc: 87.8816\n",
      "Epoch 36 / 50 ---- train_loss: 19.4889 ---- train_acc: 91.2118 ---- test_loss: 197.8720 ---- test_acc: 87.6503\n",
      "Epoch 37 / 50 ---- train_loss: 20.0291 ---- train_acc: 90.7031 ---- test_loss: 188.5331 ---- test_acc: 88.2054\n",
      "Epoch 38 / 50 ---- train_loss: 20.5467 ---- train_acc: 90.3793 ---- test_loss: 195.1577 ---- test_acc: 88.1591\n",
      "Epoch 39 / 50 ---- train_loss: 20.1240 ---- train_acc: 91.3969 ---- test_loss: 192.1683 ---- test_acc: 88.2979\n",
      "Epoch 40 / 50 ---- train_loss: 19.0947 ---- train_acc: 91.0268 ---- test_loss: 189.9591 ---- test_acc: 88.3904\n",
      "Epoch 41 / 50 ---- train_loss: 19.0006 ---- train_acc: 91.6744 ---- test_loss: 189.4714 ---- test_acc: 88.4829\n",
      "Epoch 42 / 50 ---- train_loss: 19.3596 ---- train_acc: 90.7493 ---- test_loss: 185.2348 ---- test_acc: 88.3904\n",
      "Epoch 43 / 50 ---- train_loss: 19.4583 ---- train_acc: 90.8418 ---- test_loss: 188.0942 ---- test_acc: 88.4366\n",
      "Epoch 44 / 50 ---- train_loss: 19.0588 ---- train_acc: 91.3506 ---- test_loss: 191.9274 ---- test_acc: 87.8353\n",
      "Epoch 45 / 50 ---- train_loss: 18.6662 ---- train_acc: 91.4431 ---- test_loss: 186.2983 ---- test_acc: 88.4829\n",
      "Epoch 46 / 50 ---- train_loss: 18.8704 ---- train_acc: 91.1656 ---- test_loss: 189.8140 ---- test_acc: 87.7428\n",
      "Epoch 47 / 50 ---- train_loss: 18.3233 ---- train_acc: 92.1369 ---- test_loss: 187.0689 ---- test_acc: 88.2979\n",
      "Epoch 48 / 50 ---- train_loss: 18.9338 ---- train_acc: 91.0268 ---- test_loss: 189.5997 ---- test_acc: 87.6966\n",
      "Epoch 49 / 50 ---- train_loss: 17.9920 ---- train_acc: 91.8594 ---- test_loss: 185.8877 ---- test_acc: 88.8529\n",
      "Epoch 50 / 50 ---- train_loss: 17.7453 ---- train_acc: 91.7206 ---- test_loss: 189.8648 ---- test_acc: 88.1591\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1 / 50 ---- train_loss: 116.4823 ---- train_acc: 48.3349 ---- test_loss: 653.5089 ---- test_acc: 66.6975\n",
      "Epoch 2 / 50 ---- train_loss: 68.5763 ---- train_acc: 77.3821 ---- test_loss: 445.6229 ---- test_acc: 80.3423\n",
      "Epoch 3 / 50 ---- train_loss: 53.5558 ---- train_acc: 81.9611 ---- test_loss: 367.6620 ---- test_acc: 84.2276\n",
      "Epoch 4 / 50 ---- train_loss: 45.1424 ---- train_acc: 84.4126 ---- test_loss: 334.8265 ---- test_acc: 84.4126\n",
      "Epoch 5 / 50 ---- train_loss: 40.8527 ---- train_acc: 84.5513 ---- test_loss: 306.8233 ---- test_acc: 86.1240\n",
      "Epoch 6 / 50 ---- train_loss: 37.8544 ---- train_acc: 85.7077 ---- test_loss: 283.1196 ---- test_acc: 86.3090\n",
      "Epoch 7 / 50 ---- train_loss: 36.7712 ---- train_acc: 84.5051 ---- test_loss: 270.7901 ---- test_acc: 86.8178\n",
      "Epoch 8 / 50 ---- train_loss: 33.9212 ---- train_acc: 86.6327 ---- test_loss: 258.9268 ---- test_acc: 86.4015\n",
      "Epoch 9 / 50 ---- train_loss: 32.4872 ---- train_acc: 86.7253 ---- test_loss: 240.6784 ---- test_acc: 87.6966\n",
      "Epoch 10 / 50 ---- train_loss: 31.2017 ---- train_acc: 87.7428 ---- test_loss: 236.3370 ---- test_acc: 87.8816\n",
      "Epoch 11 / 50 ---- train_loss: 30.0647 ---- train_acc: 87.4653 ---- test_loss: 226.4682 ---- test_acc: 87.6966\n",
      "Epoch 12 / 50 ---- train_loss: 30.5141 ---- train_acc: 85.9852 ---- test_loss: 220.7051 ---- test_acc: 88.5754\n",
      "Epoch 13 / 50 ---- train_loss: 29.6044 ---- train_acc: 87.0028 ---- test_loss: 232.7695 ---- test_acc: 86.3090\n",
      "Epoch 14 / 50 ---- train_loss: 28.3529 ---- train_acc: 87.6041 ---- test_loss: 220.7351 ---- test_acc: 88.1591\n",
      "Epoch 15 / 50 ---- train_loss: 28.3491 ---- train_acc: 87.1415 ---- test_loss: 218.5164 ---- test_acc: 87.1415\n",
      "Epoch 16 / 50 ---- train_loss: 26.6901 ---- train_acc: 88.6216 ---- test_loss: 216.0661 ---- test_acc: 87.4653\n",
      "Epoch 17 / 50 ---- train_loss: 26.3937 ---- train_acc: 88.4366 ---- test_loss: 208.3506 ---- test_acc: 88.3904\n",
      "Epoch 18 / 50 ---- train_loss: 26.6632 ---- train_acc: 87.7428 ---- test_loss: 207.3438 ---- test_acc: 88.2979\n",
      "Epoch 19 / 50 ---- train_loss: 25.0745 ---- train_acc: 88.6679 ---- test_loss: 204.0133 ---- test_acc: 88.7604\n",
      "Epoch 20 / 50 ---- train_loss: 25.7926 ---- train_acc: 88.5291 ---- test_loss: 202.7566 ---- test_acc: 88.0204\n",
      "Epoch 21 / 50 ---- train_loss: 24.7513 ---- train_acc: 88.7604 ---- test_loss: 210.1388 ---- test_acc: 87.0028\n",
      "Epoch 22 / 50 ---- train_loss: 24.7004 ---- train_acc: 89.0842 ---- test_loss: 198.1683 ---- test_acc: 88.8529\n",
      "Epoch 23 / 50 ---- train_loss: 23.8893 ---- train_acc: 88.9917 ---- test_loss: 205.3095 ---- test_acc: 87.5578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 50 ---- train_loss: 23.2366 ---- train_acc: 89.5005 ---- test_loss: 197.5818 ---- test_acc: 88.6216\n",
      "Epoch 25 / 50 ---- train_loss: 23.9941 ---- train_acc: 89.0379 ---- test_loss: 191.0231 ---- test_acc: 88.8529\n",
      "Epoch 26 / 50 ---- train_loss: 23.2379 ---- train_acc: 89.4542 ---- test_loss: 189.0785 ---- test_acc: 89.0842\n",
      "Epoch 27 / 50 ---- train_loss: 23.6970 ---- train_acc: 88.3904 ---- test_loss: 191.4864 ---- test_acc: 88.8992\n",
      "Epoch 28 / 50 ---- train_loss: 22.2607 ---- train_acc: 89.5005 ---- test_loss: 190.0513 ---- test_acc: 88.4366\n",
      "Epoch 29 / 50 ---- train_loss: 22.5634 ---- train_acc: 90.1943 ---- test_loss: 195.7009 ---- test_acc: 87.9741\n",
      "Epoch 30 / 50 ---- train_loss: 22.3754 ---- train_acc: 89.4542 ---- test_loss: 184.8720 ---- test_acc: 88.7142\n",
      "Epoch 31 / 50 ---- train_loss: 21.4749 ---- train_acc: 90.3793 ---- test_loss: 184.8850 ---- test_acc: 88.7604\n",
      "Epoch 32 / 50 ---- train_loss: 21.2986 ---- train_acc: 90.7493 ---- test_loss: 185.0263 ---- test_acc: 88.6216\n",
      "Epoch 33 / 50 ---- train_loss: 21.6859 ---- train_acc: 89.6392 ---- test_loss: 184.5623 ---- test_acc: 88.7142\n",
      "Epoch 34 / 50 ---- train_loss: 21.4538 ---- train_acc: 90.6568 ---- test_loss: 185.6671 ---- test_acc: 88.9454\n",
      "Epoch 35 / 50 ---- train_loss: 21.3455 ---- train_acc: 91.0731 ---- test_loss: 191.2839 ---- test_acc: 87.9278\n",
      "Epoch 36 / 50 ---- train_loss: 21.0617 ---- train_acc: 89.8705 ---- test_loss: 181.6467 ---- test_acc: 89.0842\n",
      "Epoch 37 / 50 ---- train_loss: 21.0810 ---- train_acc: 90.7956 ---- test_loss: 180.9667 ---- test_acc: 88.6216\n",
      "Epoch 38 / 50 ---- train_loss: 20.0845 ---- train_acc: 91.2118 ---- test_loss: 195.8852 ---- test_acc: 87.3728\n",
      "Epoch 39 / 50 ---- train_loss: 20.6541 ---- train_acc: 91.2118 ---- test_loss: 184.2916 ---- test_acc: 88.2054\n",
      "Epoch 40 / 50 ---- train_loss: 19.8911 ---- train_acc: 89.9630 ---- test_loss: 183.4986 ---- test_acc: 88.3904\n",
      "Epoch 41 / 50 ---- train_loss: 20.6898 ---- train_acc: 90.7031 ---- test_loss: 175.1326 ---- test_acc: 89.1767\n",
      "Epoch 42 / 50 ---- train_loss: 19.2291 ---- train_acc: 91.4431 ---- test_loss: 182.7115 ---- test_acc: 88.6216\n",
      "Epoch 43 / 50 ---- train_loss: 20.1315 ---- train_acc: 90.2868 ---- test_loss: 176.9253 ---- test_acc: 88.9917\n",
      "Epoch 44 / 50 ---- train_loss: 21.0105 ---- train_acc: 90.6105 ---- test_loss: 185.2316 ---- test_acc: 88.3441\n",
      "Epoch 45 / 50 ---- train_loss: 19.8226 ---- train_acc: 90.9806 ---- test_loss: 182.3616 ---- test_acc: 88.4366\n",
      "Epoch 46 / 50 ---- train_loss: 18.5839 ---- train_acc: 91.7206 ---- test_loss: 179.1053 ---- test_acc: 88.8992\n",
      "Epoch 47 / 50 ---- train_loss: 19.4623 ---- train_acc: 91.1193 ---- test_loss: 181.1504 ---- test_acc: 88.8067\n",
      "Epoch 48 / 50 ---- train_loss: 19.4851 ---- train_acc: 90.5643 ---- test_loss: 180.3204 ---- test_acc: 88.6216\n",
      "Epoch 49 / 50 ---- train_loss: 19.0163 ---- train_acc: 90.9343 ---- test_loss: 176.7811 ---- test_acc: 88.8067\n",
      "Epoch 50 / 50 ---- train_loss: 18.5527 ---- train_acc: 91.9056 ---- test_loss: 177.7640 ---- test_acc: 88.5754\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset)):\n",
    "    print('--------------------------------')\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    train_subsampler = SubsetRandomSampler(train_idx)\n",
    "    test_subsampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    trainloader = DataLoader(WrapperDataset(dataset,transform=train_transform),\n",
    "                            batch_size=TRAIN_BATCH_SIZE,\n",
    "                            sampler=train_subsampler)                                                                                        \n",
    "    testloader = DataLoader(WrapperDataset(dataset, transform=test_transform),\n",
    "                            batch_size=TEST_BATCH_SIZE,\n",
    "                            sampler=test_subsampler)\n",
    "    \n",
    "    model = torchvision.models.resnet152(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.fc = nn.Linear(2048, CLASS_NUM)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loss_per_epoch = []\n",
    "    train_acc_per_epoch = []\n",
    "    test_loss_per_epoch = []\n",
    "    test_acc_per_epoch = []\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model, loss_func, optimizer, device, trainloader)\n",
    "        test_loss, test_acc = test(model, loss_func, device, testloader)\n",
    "\n",
    "        train_loss_per_epoch.append(train_loss)\n",
    "        train_acc_per_epoch.append(train_acc)\n",
    "        test_loss_per_epoch.append(test_loss)\n",
    "        test_acc_per_epoch.append(test_acc)\n",
    "        \n",
    "        confusion_matrix = draw_matrix(model, device, testloader, CLASS_NUM)\n",
    "\n",
    "        print('Epoch %d / %d ---- train_loss: %0.4f ---- train_acc: %0.4f ---- test_loss: %0.4f ---- test_acc: %0.4f'\n",
    "             %(epoch+1, EPOCH, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to Name :  {0: 'americano', 1: 'bubbletea_blacksugar', 2: 'cappuccino', 3: 'caramel_macchiato', 4: 'frappuccino_javachip', 5: 'latte_Strawberry', 6: 'latte_goguma', 7: 'latte_greentea', 8: 'mango_juice'}\n",
      "--------Accuracy of Each Class--------\n",
      "americano : 96.36%\n",
      "bubbletea_blacksugar : 82.59%\n",
      "cappuccino : 81.71%\n",
      "caramel_macchiato : 84.15%\n",
      "frappuccino_javachip : 91.34%\n",
      "latte_Strawberry : 95.74%\n",
      "latte_goguma : 79.65%\n",
      "latte_greentea : 89.67%\n",
      "mango_juice : 95.04%\n"
     ]
    }
   ],
   "source": [
    "label_to_name = {v:k for k,v in dataset.class_to_idx.items()}\n",
    "print('Label to Name : ', label_to_name)\n",
    "\n",
    "confusion_matrix = draw_matrix(model, device, testloader, CLASS_NUM)\n",
    "result = confusion_matrix.diag()/confusion_matrix.sum(1)\n",
    "\n",
    "print('--------Accuracy of Each Class--------')\n",
    "for name, acc in zip(label_to_name.values(), result):\n",
    "    print('%s : %0.2f%%' %(name, acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
